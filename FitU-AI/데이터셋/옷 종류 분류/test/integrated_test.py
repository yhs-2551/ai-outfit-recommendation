from PIL import Image
import torchvision.transforms as transforms
import torch
import timm
import numpy as np
from ultralytics import YOLO
import cv2
import os

def process_segmentation(image_path, model_path, output_path):
    # YOLO ëª¨ë¸ ë¡œë“œ
    model = YOLO(model_path)
    
    # ì˜ˆì¸¡ ìˆ˜í–‰
    results = model(image_path)
    
    # ì›ë³¸ ì´ë¯¸ì§€ ì½ê¸°
    original_image = cv2.imread(image_path)
    
    # ê²°ê³¼ ì²˜ë¦¬
    for result in results:
        if result.masks is not None:
            # ë§ˆìŠ¤í¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            masks = result.masks.data.cpu().numpy()
            
            # ëª¨ë“  ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
            combined_mask = np.zeros_like(masks[0], dtype=np.uint8)
            for mask in masks:
                combined_mask = np.logical_or(combined_mask, mask)
            
            # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
            original_height, original_width = original_image.shape[:2]
            resized_mask = cv2.resize(combined_mask.astype(np.uint8), 
                                    (original_width, original_height), 
                                    interpolation=cv2.INTER_NEAREST)
            
            # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
            mask_3channel = np.stack([resized_mask] * 3, axis=-1)
            
            # ë§ˆìŠ¤í¬ ì ìš© (ì˜· ë¶€ë¶„ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” í°ìƒ‰ìœ¼ë¡œ)
            segmented_image = np.where(mask_3channel, original_image, 255)
            
            # ë§ˆìŠ¤í¬ì˜ ê²½ê³„ ìƒì ì°¾ê¸°
            y_indices, x_indices = np.where(resized_mask)
            if len(y_indices) > 0 and len(x_indices) > 0:
                y_min, y_max = y_indices.min(), y_indices.max()
                x_min, x_max = x_indices.min(), x_indices.max()
                
                # íŒ¨ë”© ì¶”ê°€ (ì´ë¯¸ì§€ í¬ê¸°ì˜ 10%)
                padding_y = int((y_max - y_min) * 0.1)
                padding_x = int((x_max - x_min) * 0.1)
                
                # íŒ¨ë”©ì„ ì ìš©í•œ ìƒˆë¡œìš´ ê²½ê³„ ìƒì ê³„ì‚°
                y_min = max(0, y_min - padding_y)
                y_max = min(original_height - 1, y_max + padding_y)
                x_min = max(0, x_min - padding_x)
                x_max = min(original_width - 1, x_max + padding_x)
                
                # ì˜· ë¶€ë¶„ë§Œ í¬ë¡­
                cropped_image = segmented_image[y_min:y_max+1, x_min:x_max+1]
                
                # 640x640 í°ìƒ‰ ë°°ê²½ ìƒì„±
                final_image = np.ones((640, 640, 3), dtype=np.uint8) * 255
                
                # í¬ë¡­ëœ ì´ë¯¸ì§€ì˜ í¬ê¸° ê³„ì‚°
                h, w = cropped_image.shape[:2]
                
                # ì´ë¯¸ì§€ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ 640x640ì— ë§ê²Œ ë¦¬ì‚¬ì´ì¦ˆ
                scale = min(640/w, 640/h)
                new_w, new_h = int(w * scale), int(h * scale)
                resized_crop = cv2.resize(cropped_image, (new_w, new_h), interpolation=cv2.INTER_AREA)
                
                # ì¤‘ì•™ì— ë°°ì¹˜
                y_offset = (640 - new_h) // 2
                x_offset = (640 - new_w) // 2
                final_image[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized_crop
                
                # ê²°ê³¼ ì €ì¥
                cv2.imwrite(output_path, final_image)
                print(f"ì²˜ë¦¬ëœ ì´ë¯¸ì§€ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
    test_image_path = "ë°ì´í„°ì…‹\ì˜· ì¢…ë¥˜ ë¶„ë¥˜/01.ì›ì²œë°ì´í„°\VS_ìƒí’ˆ_ìƒì˜_coat/01_sou_000014_000066_front_01outer_01coat_woman.jpg"
    
    # 1. ë¶„ë¥˜ ëª¨ë¸ ë¡œë“œ ë° ì˜ˆì¸¡
    DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = timm.create_model('efficientnetv2_s', pretrained=False, num_classes=3)
    model.load_state_dict(torch.load("ë°ì´í„°ì…‹/ì˜· ì¢…ë¥˜ ë¶„ë¥˜/model/classification_efficientnetv2_s.pt", map_location=DEVICE))
    model.to(DEVICE)
    model.eval()

    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    transform = transforms.Compose([
        transforms.Resize((640, 640)),
        transforms.ToTensor(),
    ])

    image = Image.open(test_image_path).convert("RGB")
    input_tensor = transform(image).unsqueeze(0).to(DEVICE)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    with torch.no_grad():
        output = model(input_tensor)
        probs = torch.sigmoid(output).cpu().numpy()[0]
        preds = (probs > 0.5).astype(int)

    # ë¼ë²¨ ë§¤í•‘
    classes = ['top', 'bottom', 'onepiece']
    results = [(cls, int(p), round(prob, 3)) for cls, p, prob in zip(classes, preds, probs)]

    # ê²°ê³¼ ì¶œë ¥
    print("ğŸ” ë¶„ë¥˜ ê²°ê³¼:")
    detected_classes = []
    for label, is_present, confidence in results:
        status = "âœ… ìˆìŒ" if is_present else "âŒ ì—†ìŒ"
        print(f"{label:<10}: {status} (score: {confidence})")
        if is_present:
            detected_classes.append(label)

    # 2. ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
    model_paths = {
        'top': "ë°ì´í„°ì…‹/ì˜· ì¢…ë¥˜ ë¶„ë¥˜/model/top_yolo11seg_m.pt",
        'bottom': "ë°ì´í„°ì…‹/ì˜· ì¢…ë¥˜ ë¶„ë¥˜/model/bottom_yolo11seg_m.pt",
        'onepiece': "ë°ì´í„°ì…‹/ì˜· ì¢…ë¥˜ ë¶„ë¥˜/model/onepiece_yolo11seg_m.pt"
    }

    # ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = "ë°ì´í„°ì…‹/ì˜· ì¢…ë¥˜ ë¶„ë¥˜/test"
    os.makedirs(output_dir, exist_ok=True)

    # ê° ê°ì§€ëœ í´ë˜ìŠ¤ì— ëŒ€í•´ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
    for cls in detected_classes:
        if cls in model_paths:
            output_path = os.path.join(output_dir, f"seg_result_{cls}.jpg")
            process_segmentation(test_image_path, model_paths[cls], output_path)

if __name__ == "__main__":
    main() 